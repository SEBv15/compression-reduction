{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9a28cbc31159c186f080eee2158b8a6e07b338e2dcc91a216d19ef798b67e5e2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Estimate Compression Ratio\n",
    "\n",
    "This notebook estimates the compression ratio of the CompressionReduction module using data from other detectors which was manipulated to look more like the expected data from this detector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from math import ceil\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "source": [
    "Declare which files we want to estimate the compression ratio with. They should be the names of the `.bin` files in the `data/` folder. They can be obtained [here](https://anl.box.com/s/folizdpti1i95oz7yxclvheoysq5fmhf)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [\"pilatus\", \"ptychography\", \"xpcs\"]"
   ]
  },
  {
   "source": [
    "## Make plots for one of the files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Dropdown(description='File:', options=(('pilatus', 0), ('ptychography', 1), ('xpcs', 2)), value=0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9214172bfb36489b9c9f0d2efca7ca5c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "dropdown = widgets.Dropdown(\n",
    "    options=[(n, i) for i, n in enumerate(data_files)],\n",
    "    value=0,\n",
    "    description='File:',\n",
    ")\n",
    "dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimating compression using pilatus data\n"
     ]
    }
   ],
   "source": [
    "filename = data_files[dropdown.value]\n",
    "print(f'Estimating compression using {filename} data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_reduced_size(shift: np.ndarray, use_poisson: bool = True) -> int:\n",
    "    compressed = np.zeros((64, 8 if use_poisson else 11), dtype=np.uint64)\n",
    "    i = 0\n",
    "    for row in range(0, 128, 4):\n",
    "        for col in range(0, 8, 4):\n",
    "            data = shift[col:col+4, row:row+4].flatten()\n",
    "            poisson_encoded = poisson_encode(data)\n",
    "            compressed_elem = length_shuffle_compress(poisson_encoded, bits_per_pixel = 7 if use_poisson else 10)\n",
    "            compressed[i][0:compressed_elem.shape[0]] = compressed_elem\n",
    "            i += 1\n",
    "    [h_2bit, h_3bit, reduced] = reduce_data(compressed, maxblocks = 128, data_len = 7 if use_poisson else 10)\n",
    "\n",
    "    return h_2bit.shape[0]*2 + ceil(h_3bit.shape[0]*(3 if use_poisson else 4)/16)*16 + reduced.shape[0]*16\n",
    "\n",
    "def get_reduced_sizes(filename: str, use_poisson: bool = True):\n",
    "    reduced_sizes = []\n",
    "    for frame in get_frames(f'data/{filename}.bin'):\n",
    "        for shift_col in range(0, 128, 8):\n",
    "            shift = frame[shift_col:shift_col+8]\n",
    "            reduced_sizes.append(get_reduced_size(shift, use_poisson=use_poisson))\n",
    "    return reduced_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4dc4f033c8a4f448f430c3dca1d5b5d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Get the size (in bits) of every reduced shift in every frame\n",
    "reduced_sizes = get_reduced_sizes(filename)\n",
    "\n",
    "uncompressed_size = 128*8*10\n",
    "\n",
    "%matplotlib widget\n",
    "plt.plot([uncompressed_size/s for s in reduced_sizes], label=\"Compression Ratio\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Shift Number\")\n",
    "plt.ylabel(\"Compression Ratio\")\n",
    "plt.title(\"Compression Ratio after Reduction for every shift\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afba2e55484447c592c93dd326289de6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "def get_fifo_write_sizes(reduced_sizes):\n",
    "    fifo_write_sizes = []\n",
    "    merge_buffer = 0\n",
    "    for s in reduced_sizes:\n",
    "        s = ceil(s/4)*4 # EnsureBlocks uses 64-bit elements instead of 16-bit\n",
    "\n",
    "        # Check if we need to write to FIFO\n",
    "        if merge_buffer + s > (1024 - 8)*10:\n",
    "            fifo_write_sizes.append(ceil(merge_buffer/(1024-8))*1024)\n",
    "            merge_buffer = 0\n",
    "        else:\n",
    "            fifo_write_sizes.append(0)\n",
    "\n",
    "        merge_buffer += s\n",
    "    return fifo_write_sizes\n",
    "\n",
    "fifo_write_sizes = get_fifo_write_sizes(reduced_sizes)\n",
    "\n",
    "%matplotlib widget\n",
    "plt.plot(fifo_write_sizes, label=\"FIFO write sizes\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Tick Number\")\n",
    "plt.ylabel(\"# bits\")\n",
    "plt.title(\"FIFO write size for every tick\")\n",
    "plt.show()            "
   ]
  },
  {
   "source": [
    "## Overall compression ratios"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Estimated using pilatus data"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With poisson encoding: 5.37694634255629\n",
      "Without poisson encoding: 5.1183621241202815\n",
      "Before merging (with poisson): 5.680420854097133\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Estimated using ptychography data"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With poisson encoding: 29.165704690943436\n",
      "Without poisson encoding: 25.16935337801123\n",
      "Before merging (with poisson): 30.05043073081478\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Estimated using xpcs data"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With poisson encoding: 8.133659331703342\n",
      "Without poisson encoding: 7.61723035825025\n",
      "Before merging (with poisson): 8.514478626155174\n"
     ]
    }
   ],
   "source": [
    "for filename in data_files:\n",
    "    printmd(f'### Estimated using {filename} data')\n",
    "\n",
    "    reduced = get_reduced_sizes(filename)\n",
    "    fifo_sizes = get_fifo_write_sizes(reduced)\n",
    "    print(f\"With poisson encoding: {uncompressed_size*len(fifo_sizes)/sum(fifo_sizes)}\")\n",
    "\n",
    "    reduced_np = get_reduced_sizes(filename, use_poisson=False)\n",
    "    fifo_sizes_np = get_fifo_write_sizes(reduced_np)\n",
    "    print(f\"Without poisson encoding: {uncompressed_size*len(fifo_sizes_np)/sum(fifo_sizes_np)}\")\n",
    "\n",
    "    print(f'Before merging (with poisson): {uncompressed_size*len(reduced)/sum(reduced)}')\n"
   ]
  }
 ]
}